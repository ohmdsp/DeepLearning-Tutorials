{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning - Autoencoders\n",
    "by [David Ohm](http://ohmdsp.github.io/)\n",
    "/ [GitHub](https://github.com/ohmdsp)\n",
    "\n",
    "In this notebook, we will explore some neural networks for unsupervised learning. This will give us some tools to explore data in some very interesting ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning with deep neural networks can be classified into two categories:  (1) Unsupervised Learning - You have a lot of data and you want to learn something about the data (e.g., patterns, clustering, reduce dimensionality, generating new data, etc.), and (2) Supervised Learning - You know what you want to learn using your data and you have labeled training data.  We are going to explore the autoencoder.\n",
    "\n",
    "## Autoencoders\n",
    "\n",
    "![Autoencoder](images/autoencoder.png)\n",
    "\n",
    "An autoencoder is a type of neural network that learns to encode a lower dimension representation of its input data.  It can also reproduce the original input data using a decoding process. An autoencoder does not require \"labels\" to learn.  Instead, it tries to generate an output that is the same as the input. For example, if an image is input, the output from the decoder will be the same image. In this notebook, we will see why this is interesting. \n",
    "\n",
    "It is worth mentioning two interesting practical applications of autoencoders: (1)data denoising, and (2)dimensionality reduction for data visualization. In many cases, autoencoders can learn data projections that are more interesting than PCA or other basic techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "# Some additional libraries to produce some visualizations for training\n",
    "from PIL import Image\n",
    "from libs.utils import montage\n",
    "#from libs import gif\n",
    "#import IPython.display as ipyd\n",
    "plt.style.use('ggplot')\n",
    "#from PIL import Image\n",
    "\n",
    "#import keras\n",
    "from keras.layers import Activation, Dense, Input, Lambda, Layer\n",
    "from keras.layers import Conv2D, Flatten, MaxPooling2D, UpSampling2D\n",
    "from keras.layers import Reshape, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras import backend as K\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in some MNIST data to use for examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 1000 images from the training set for dispay\n",
    "images = x_train[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at one of these images\n",
    "img = x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can display a montage of the 1000 images from this training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (14,10)   # set plot sizes\n",
    "# Then create a montage and draw the montage\n",
    "plt.imshow(montage(images), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like we did in the preprocessing notebook, let's take a look at the mean of 1000 images from this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the mean across all 1000 images\n",
    "mean_img = np.mean(images, axis=0)\n",
    "\n",
    "# Then plot the mean image.\n",
    "plt.figure()\n",
    "plt.imshow(mean_img.reshape((28, 28)), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Simple Autoencoder  - Fully Connected Model\n",
    "\n",
    "We will start with the most basic autoencoder using a fully connected model.  From the original 784 (i.e., 28x28) neurons, we're going to reduce the image dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the dimension to reduce the original image(s) to\n",
    "encoding_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder for input\n",
    "input_img = Input(shape = (784,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create autoencoder model\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "autoencoder = Model(input_img, decoded) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create seperate encoder model\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create decoder model\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the autoencoder model to use per-pixel crossentropy loss and an optimizer\n",
    "autoencoder.compile(optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.0), loss='binary_crossentropy')\n",
    "#autoencoder.compile(optimizer=tf.keras.optimizers.Adam(lr=.001), loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data for training\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the autoencoder training\n",
    "history = autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Binary Cross Entropy')\n",
    "plt.ylim([0,max(plt.ylim())])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode and decode some digits. Note: we use images from the test dataset\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare some input images to their output images from the autoencoder. You will see that the image reconstruction is not perfect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, the latent representations of our input images have been constrained by the size of the hidden layer of 32. With a simple neural network like this, the hidden layer is learning an approximation of PCA (principal component analysis). \n",
    "\n",
    "Another way we can  constrain the representations to be small (e.g., compressed) is to add a sparsity contraint on the activation function of the hidden layer, so fewer neurons will \"fire\" each computation. In Keras, this can be done by adding an activity_regularizer to our Dense layer (see next cell). We will not explore this here, but you can experiment on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a Dense layer with a L1 activity regularizer\n",
    "#encoded = Dense(encoding_dim, activation='relu',\n",
    "#                activity_regularizer=regularizers.l1(10e-5))(input_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Autonencoder\n",
    "\n",
    "We are not limited to a single layer in the encoder. We could add a stack of layers - making the network deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear the previous model\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(128, activation='relu')(input_img)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer=tf.keras.optimizers.Adadelta(lr=1.0), loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(x_train, x_train,\n",
    "                epochs=20,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Binary Cross Entropy')\n",
    "plt.ylim([0,max(plt.ylim())])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode and decode some digits from test set\n",
    "decoded_imgs = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deeper model looks to generate slightly better results, but it is not a dramatic improvement over the simple model. Let's look at using convolutional layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoder\n",
    "Since our inputs are images, it makes sense to use convolutional neural networks as encoders and decoders. In practical settings, autoencoders applied to images are always convolutional autoencoders -- they simply perform much better.\n",
    "\n",
    "Let's implement a convolutional autoencoder to see how it performs. The encoder will consist in a stack of Conv2D and MaxPooling2D layers (max pooling being used for spatial down-sampling), while the decoder will consist in a stack of Conv2D and UpSampling2D layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear the previous model\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our encoder network\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our decoder network\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer=tf.keras.optimizers.Adadelta(lr=1.0), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.callbacks import TensorBoard\n",
    "\n",
    "history = autoencoder.fit(x_train, x_train,\n",
    "                epochs=20,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Binary Cross Entropy')\n",
    "plt.ylim([0,max(plt.ylim())])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode and decode some digits from test set\n",
    "decoded_imgs = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from the convolutional autoencoder are better. It is especially apparent with the 9 and 2 digits.\n",
    "\n",
    "We can also look at the encoded representations. These are shaped as 8x4x4 so we need to reshape them to 4x32 to display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create seperate encoder model\n",
    "encoder = Model(input_img, encoded)\n",
    "encoded_imgs = encoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(14, 8))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(encoded_imgs[i].reshape(4, 4 * 8).T)\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Denoising Autoencoder\n",
    "\n",
    "The denoising autoencoder is a very simple extension to an autoencoder, and it can be a useful tool in the hands of a signal processing engineer.  We will use an convolutional autoencoder to work on a toy image denoising problem. We will train the autoencoder to map noisy digits images to clean digits images. Note - we will simulate the noisy data by adding noise to images from the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear the previous model\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate noisy MNIST images by adding noise with normal dist centered at 0.5 and variance of 0.5\n",
    "noise = np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
    "x_train_noisy = x_train + 0.5*noise\n",
    "noise = np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "x_test_noisy = x_test + 0.5*noise\n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some of the noisy digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i+1)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a slightly different model for denoising that has more filters per layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(28, 28, 1))\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (7, 7, 32)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer=tf.keras.optimizers.Adadelta(lr=1.0), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=25,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Binary Cross Entropy')\n",
    "plt.ylim([0,max(plt.ylim())])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the Autoencoder output from corrupted test images\n",
    "decoded_imgs = autoencoder.predict(x_test_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoder (VAE)\n",
    "\n",
    "A variational autoencoder a type of autoencoder with constraints on the encoded representations that can be learned. It learns a latent variable model for the input data. So, instead of letting your neural network learn an arbitrary function, you are learning the parameters of a probability distribution for modeling your data. If you sample points from this distribution, you can generate new input data samples. For this reason a VAE is considered a \"generative model\".\n",
    "\n",
    "How does a variational autoencoder work?\n",
    "\n",
    "First, an encoder network turns the input samples x into two parameters in a latent space, which we will note z_mean and z_log_sigma (i.e., the mean and log of variance for a normal distribution). Then, we randomly sample points z from that latent normal distribution, using z = z_mean + exp(z_log_sigma) * epsilon, where epsilon is a random normal distribution. Finally, a decoder network maps these latent space points back to the original input data.\n",
    "\n",
    "The parameters of the nearal network are trained via two loss functions: a reconstruction loss forcing the decoded samples to match the initial inputs (just like in our previous autoencoders), and the KL divergence between the learned latent distribution and the prior distribution, acting as a regularization term. It is not required to use the KL term, although it helps in learning well-formed latent spaces and reducing overfitting to the training data.\n",
    "\n",
    "Let's build one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear the previous model\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "image_size = x_train.shape[1]\n",
    "original_dim = image_size * image_size\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "input_shape = (original_dim, )\n",
    "print(input_shape)\n",
    "intermediate_dim = 512\n",
    "batch_size = 100\n",
    "latent_dim = 2\n",
    "epochs = 50\n",
    "epsilon_std = 1.0 # standard deviation of normal distribution used to sample latent values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE model = encoder + decoder\n",
    "x = Input(shape= (original_dim,))\n",
    "h = Dense(intermediate_dim, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(h)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
    "\n",
    "    # Arguments - args (tensor): mean and log of variance of Q(z|X)\n",
    "\n",
    "    # Returns - z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean = 0 and std = 1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim),mean=0.,stddev=epsilon_std)\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reparameterization trick to push the sampling out as input\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build decoder model\n",
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss layer\n",
    "class CustomVariationalLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def vae_loss(self, x, x_decoded_mean):\n",
    "        xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n",
    "        kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        return K.mean(xent_loss + kl_loss)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        x_decoded_mean = inputs[1]\n",
    "        loss = self.vae_loss(x, x_decoded_mean)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We won't actually use the output.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def vae_loss(x, x_decoded_mean):\n",
    "#    xent_loss = original_dim * binary_crossentropy(x, x_decoded_mean)\n",
    "#    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "#    return k.mean(xent_loss + kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = CustomVariationalLayer()([x, x_decoded_mean])\n",
    "vae = Model(x, y)\n",
    "vae.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=.001), loss=None)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can create an anomoly\n",
    "For fun and exploration, let's remove a digit from the dataset to simulate an anomoly. We can explore methods for anomoly detection later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalous_digit = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove anomalous digit from train data\n",
    "train_mask = np.where(y_train!=anomalous_digit)[0]\n",
    "x_train = x_train[train_mask, :]\n",
    "y_train = y_train[train_mask]\n",
    "\n",
    "# create binary labels\n",
    "test_mask = np.where(y_test != anomalous_digit)[0]\n",
    "y_test_binary = np.zeros(y_test.shape[0])\n",
    "y_test_binary[test_mask] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = vae.fit(x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "#val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(loss, label='Training Loss')\n",
    "#plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('VAE Custom Loss')\n",
    "plt.ylim([0,max(plt.ylim())])\n",
    "#plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Learned Latent Distribution\n",
    "\n",
    "A variational autoencoder allows us to inspect the latent space to learn more about our model and our data.  For example, in anomaly detection, latent variables can be used to try and determine the cause of anomalies.  \n",
    "In the case that we have 2 latent dimensions we can easily visualize the representation.  With higher dimensionality we can use dimensionality reducing techniques such as PCA or t-SNE to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model to project inputs on to the latent space\n",
    "encoder = Model(x, z_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if latent_dim == 2:\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test, cmap='viridis_r')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a digit generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a 2D manifold of the digits\n",
    "from scipy.stats import norm\n",
    "epsilon_std = 1\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# we will sample n points within [-15, 15] standard deviations\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = generator.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit       \n",
    "        \n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection\n",
    "\n",
    "We detect anomalies by computing the probability that our reconstructed datapoint came from the ground truth.  To do this, we reconstruct (run through autoencoder) all of the data in our test set and then compute the binary cross-entropy between ground truth digits and our reconstruction.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute sigmoid output of the autoencoder (without variational parts)\n",
    "sigmoid_output = Model(x, x_decoded_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute reconstructions of the test set\n",
    "x_test_recons = sigmoid_output.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the likelihood of our reconstruction we compute exponential of the negative cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recon_prob(output, target):\n",
    "    xent = -(target*np.log(output + .0000001) + (1.0 - target) * np.log(1.0 - output + .0000001))\n",
    "    xent = np.mean(xent, axis=1)\n",
    "    return np.exp(-xent)\n",
    "\n",
    "probs = recon_prob(x_test_recons, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can learn about the effectiveness of our anomaly detector by visualizing the results.  Below we randomly sample ten images at a time from the test set, then display the original image with the output reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot original digit, reconstruction, and probability\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n+1):\n",
    "    img_idx = np.random.randint(0,y_test.shape[0])\n",
    "    print('image index: ' + str(img_idx) +\n",
    "          ' normal: ' + str(y_test_binary[img_idx]) + \n",
    "          ' probability: ' + str(probs[img_idx]))\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[img_idx].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(x_test_recons[img_idx].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be instructive to visualize what are the most normal images in our test set according to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot n highest probability reconstructions\n",
    "n = 10\n",
    "ten_highest = np.argpartition(-probs, n)\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1,n+1):\n",
    "    img_idx = ten_highest[i-1]\n",
    "    print('image index: ' + str(img_idx) +\n",
    "          ' normal: ' + str(y_test_binary[img_idx]) + \n",
    "          ' probability: ' + str(probs[img_idx]))\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[img_idx].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(x_test_recons[img_idx].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also helpful to visualize what are the most anomalous images according to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot n lowest probability reconstructions\n",
    "n = 10\n",
    "ten_highest = np.argpartition(probs, n)\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1,n+1):\n",
    "    img_idx = ten_highest[i-1]\n",
    "    print('image index: ' + str(img_idx) +\n",
    "          ' normal: ' + str(y_test_binary[img_idx]) + \n",
    "          ' probability: ' + str(probs[img_idx]))\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[img_idx].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(x_test_recons[img_idx].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__: what can you say about the probabilities of your most anomalous digits?\n",
    "\n",
    "__Try This__: Change the anomalous digit and retrain the model.  Is the anomaly detection model effective for digit?\n",
    "\n",
    "__Try This__: Retrain the VAE without removing an anomalous digit. What do you notice about the images that are found to be anomalous?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "To evaluate the effectiveness of the model, we can use a ROC curve and compute the AUC (area-under-the-curve).  A diagonal line represents the performance similar to random chance (i.e., flipping a coin).  A quickly rising ROC curve indicates a well performing model.  Similarly, an AUC of .5 means random chance and a quickly rising AUC means the model is performing well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the ROC curves\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "auc = roc_auc_score(y_test_binary, probs)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_binary, probs)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b',\n",
    "label='AUC = %0.2f'% auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__: How does the anomolous digit affect the AUC after retraining?\n",
    "\n",
    "Since we learned the distribution underlying our data using the VAE, we can repeatedly sample the distribution to generate more data.  The more we sample, the lower variance our probability estimate will have due to averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute reconstruction probabilities with lower variance. Note: this takes some time to compute.\n",
    "num_samples = 100\n",
    "all_probs = np.zeros((x_test.shape[0], num_samples))\n",
    "for i in range(num_samples):\n",
    "    \n",
    "    x_test_recons = sigmoid_output.predict(x_test)\n",
    "    \n",
    "    probs = recon_prob(x_test_recons, x_test)\n",
    "\n",
    "    all_probs[:, i] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_probs = np.mean(all_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_with_sampling = roc_auc_score(y_test_binary, mean_probs)\n",
    "print('auc with sampling: ' + str(auc_with_sampling))\n",
    "print('auc: ' + str(auc))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test_binary, mean_probs)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b',\n",
    "label='AUC = %0.2f'% auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, for this example there is not much difference in the ROC from generating more data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "02b27af3a7ebd1925d3428a05ae25ced2862209cfd7f625658a70574b2dafdf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
